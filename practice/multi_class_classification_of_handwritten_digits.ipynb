{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multi-class_classification_of_handwritten_digits.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "266KQvZoMxMv",
        "6sfw3LH0Oycm",
        "copyright-notice"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/SarahhhC/ml-study/blob/master/practice/multi_class_classification_of_handwritten_digits.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "copyright-notice",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Copyright 2017 Google LLC."
      ]
    },
    {
      "metadata": {
        "id": "copyright-notice2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mPa95uXvcpcn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " # 신경망으로 필기 입력된 숫자 분류하기"
      ]
    },
    {
      "metadata": {
        "id": "Fdpn8b90u8Tp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " ![img](https://www.tensorflow.org/versions/r0.11/images/MNIST.png)"
      ]
    },
    {
      "metadata": {
        "id": "c7HLCm66Cs2p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " **학습 목표:**\n",
        "  * 선형 모델과 신경망을 모두 학습시켜 기존 [MNIST](http://yann.lecun.com/exdb/mnist/) 데이터 세트의 필기 입력된 숫자를 분류한다\n",
        "  * 선형 모델과 신경망 분류 모델의 성능을 비교한다\n",
        "  * 신경망 히든 레이어의 가중치를 시각화한다"
      ]
    },
    {
      "metadata": {
        "id": "HSEh-gNdu8T0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " 이번 목표는 각각의 입력 이미지를 올바른 숫자에 매핑하는 것입니다. 몇 개의 히든 레이어를 포함하며 소프트맥스 레이어가 맨 위에서 최우수 클래스를 선택하는 NN을 만들어 보겠습니다."
      ]
    },
    {
      "metadata": {
        "id": "2NMdE1b-7UIH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " ## 설정\n",
        "\n",
        "우선 데이터 세트를 다운로드하고, 텐서플로우 및 기타 유틸리티 모듈을 import로 불러오고, 데이터를 *pandas* `DataFrame`에 로드합니다. 이 데이터는 원본 MNIST 학습 데이터에서 20,000개 행을 무작위로 추출한 샘플입니다."
      ]
    },
    {
      "metadata": {
        "id": "4LJ4SD8BWHeh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "918004b1-c53b-4595-8871-064cddeffab0"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import glob\n",
        "import math\n",
        "import os\n",
        "\n",
        "from IPython import display\n",
        "from matplotlib import cm\n",
        "from matplotlib import gridspec\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.data import Dataset\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = '{:.1f}'.format\n",
        "\n",
        "mnist_dataframe = pd.read_csv(\n",
        "  \"https://dl.google.com/mlcc/mledu-datasets/mnist_train_small.csv\",\n",
        "  sep=\",\",\n",
        "  header=None)\n",
        "\n",
        "# Use just the first 10,000 records for training/validation\n",
        "mnist_dataframe = mnist_dataframe.head(10000)\n",
        "\n",
        "mnist_dataframe = mnist_dataframe.reindex(np.random.permutation(mnist_dataframe.index))\n",
        "mnist_dataframe.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "      <th>784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2819</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4926</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5041</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7844</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9077</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      0    1    2    3    4    5    6    7    8    9   ...   775  776  777  \\\n",
              "2819    6    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
              "4926    6    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
              "5041    9    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
              "7844    5    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
              "9077    7    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
              "\n",
              "      778  779  780  781  782  783  784  \n",
              "2819    0    0    0    0    0    0    0  \n",
              "4926    0    0    0    0    0    0    0  \n",
              "5041    0    0    0    0    0    0    0  \n",
              "7844    0    0    0    0    0    0    0  \n",
              "9077    0    0    0    0    0    0    0  \n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "kg0-25p2mOi0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " 첫 번째 열은 클래스 라벨을 포함합니다. 나머지 열은 특성 값을 포함하며, `28×28=784`개 픽셀 값마다 각각 하나의 특성 값이 됩니다.  이 784개의 픽셀 값은 대부분 0이지만, 1분 정도 시간을 들여 모두 0은 아니라는 것을 확인하시기 바랍니다."
      ]
    },
    {
      "metadata": {
        "id": "PQ7vuOwRCsZ1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " ![img](https://www.tensorflow.org/versions/r0.11/images/MNIST-Matrix.png)"
      ]
    },
    {
      "metadata": {
        "id": "dghlqJPIu8UM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " 이러한 예는 비교적 해상도가 낮고 대비가 높은 필기 입력 숫자입니다. `0-9` 범위의 숫자 10개가 각각 표현되었으며 가능한 각 숫자에 고유한 클라스 라벨이 지정됩니다. 따라서 이 문제는 10개 클래스를 대상으로 하는 다중 클래스 분류 문제입니다.\n",
        "\n",
        "이제 라벨과 특성을 해석하고 몇 가지 예를 살펴보겠습니다. 이 데이터 세트에는 헤더 행이 없지만 `loc`를 사용하여 원래 위치를 기준으로 열을 추출할 수 있습니다."
      ]
    },
    {
      "metadata": {
        "id": "JfFWWvMWDFrR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def parse_labels_and_features(dataset):\n",
        "  \"\"\"Extracts labels and features.\n",
        "  \n",
        "  This is a good place to scale or transform the features if needed.\n",
        "  \n",
        "  Args:\n",
        "    dataset: A Pandas `Dataframe`, containing the label on the first column and\n",
        "      monochrome pixel values on the remaining columns, in row major order.\n",
        "  Returns:\n",
        "    A `tuple` `(labels, features)`:\n",
        "      labels: A Pandas `Series`.\n",
        "      features: A Pandas `DataFrame`.\n",
        "  \"\"\"\n",
        "  labels = dataset[0]\n",
        "\n",
        "  # DataFrame.loc index ranges are inclusive at both ends.\n",
        "  features = dataset.loc[:,1:784]\n",
        "  # Scale the data to [0, 1] by dividing out the max value, 255.\n",
        "  features = features / 255\n",
        "\n",
        "  return labels, features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mFY_-7vZu8UU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "0def8802-43ea-458c-e4f9-2a846f1fad48"
      },
      "cell_type": "code",
      "source": [
        "training_targets, training_examples = parse_labels_and_features(mnist_dataframe[:7500])\n",
        "training_examples.describe()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "      <th>784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>...</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         1      2      3      4      5      6      7      8      9      10   \\\n",
              "count 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0   \n",
              "mean     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "std      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "min      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "25%      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "50%      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "75%      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "max      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "\n",
              "       ...      775    776    777    778    779    780    781    782    783  \\\n",
              "count  ...   7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0   \n",
              "mean   ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "std    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "min    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "25%    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "50%    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "75%    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "max    ...      1.0    1.0    0.8    0.2    1.0    0.2    0.0    0.0    0.0   \n",
              "\n",
              "         784  \n",
              "count 7500.0  \n",
              "mean     0.0  \n",
              "std      0.0  \n",
              "min      0.0  \n",
              "25%      0.0  \n",
              "50%      0.0  \n",
              "75%      0.0  \n",
              "max      0.0  \n",
              "\n",
              "[8 rows x 784 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "4-Vgg-1zu8Ud",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "9b40bba8-ef0d-45c2-e7e1-94d95024726c"
      },
      "cell_type": "code",
      "source": [
        "validation_targets, validation_examples = parse_labels_and_features(mnist_dataframe[7500:10000])\n",
        "validation_examples.describe()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "      <th>784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         1      2      3      4      5      6      7      8      9      10   \\\n",
              "count 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0   \n",
              "mean     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "std      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "min      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "25%      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "50%      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "75%      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "max      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "\n",
              "       ...      775    776    777    778    779    780    781    782    783  \\\n",
              "count  ...   2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0   \n",
              "mean   ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "std    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "min    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "25%    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "50%    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "75%    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "max    ...      0.9    1.0    0.3    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "\n",
              "         784  \n",
              "count 2500.0  \n",
              "mean     0.0  \n",
              "std      0.0  \n",
              "min      0.0  \n",
              "25%      0.0  \n",
              "50%      0.0  \n",
              "75%      0.0  \n",
              "max      0.0  \n",
              "\n",
              "[8 rows x 784 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "wrnAI1v6u8Uh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " 무작위로 선택한 예 및 해당 라벨을 표시합니다."
      ]
    },
    {
      "metadata": {
        "id": "s-euVJVtu8Ui",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "5a2085bf-bcf3-452f-de4b-327a825ab23d"
      },
      "cell_type": "code",
      "source": [
        "rand_example = np.random.choice(training_examples.index)\n",
        "_, ax = plt.subplots()\n",
        "ax.matshow(training_examples.loc[rand_example].values.reshape(28, 28))\n",
        "ax.set_title(\"Label: %i\" % training_targets.loc[rand_example])\n",
        "ax.grid(False)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFXCAYAAAAro2x+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fa6588c4a90>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ScmYX7xdZMXE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " ## 작업 1: MNIST용 선형 모델 구축\n",
        "\n",
        "우선 비교 기준이 될 모델을 만듭니다. `LinearClassifier`는 *k*개 클래스마다 하나씩 *k*개의 일대다 분류자 집합을 제공합니다.\n",
        "\n",
        "이 작업에서는 정확성을 보고하고 시간별 로그 손실을 도식화할 뿐 아니라 [**혼동행렬**](https://en.wikipedia.org/wiki/Confusion_matrix)도 표시합니다. 혼동행렬은 다른 클래스로 잘못 분류된 클래스를 보여줍니다. 서로 혼동하기 쉬운 숫자는 무엇일까요?\n",
        "\n",
        "또한 `log_loss` 함수를 사용하여 모델의 오차를 추적합니다. 이 함수는 학습에 사용되는 `LinearClassifier` 내장 손실 함수와 다르므로 주의하시기 바랍니다."
      ]
    },
    {
      "metadata": {
        "id": "cpoVC4TSdw5Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def construct_feature_columns():\n",
        "  \"\"\"Construct the TensorFlow Feature Columns.\n",
        "\n",
        "  Returns:\n",
        "    A set of feature columns\n",
        "  \"\"\" \n",
        "  \n",
        "  # There are 784 pixels in each image \n",
        "  return set([tf.feature_column.numeric_column('pixels', shape=784)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kMmL89yGeTfz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " 여기에서는 학습과 예측의 입력 함수를 서로 다르게 만들겠습니다. 각각 `create_training_input_fn()` 및 `create_predict_input_fn()`에 중첩시키고 이러한 함수를 호출할 때 반환되는 해당 `_input_fn`을 `.train()` 및 `.predict()` 호출에 전달하면 됩니다."
      ]
    },
    {
      "metadata": {
        "id": "OeS47Bmn5Ms2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_training_input_fn(features, labels, batch_size, num_epochs=None, shuffle=True):\n",
        "  \"\"\"A custom input_fn for sending MNIST data to the estimator for training.\n",
        "\n",
        "  Args:\n",
        "    features: The training features.\n",
        "    labels: The training labels.\n",
        "    batch_size: Batch size to use during training.\n",
        "\n",
        "  Returns:\n",
        "    A function that returns batches of training features and labels during\n",
        "    training.\n",
        "  \"\"\"\n",
        "  def _input_fn(num_epochs=None, shuffle=True):\n",
        "    # Input pipelines are reset with each call to .train(). To ensure model\n",
        "    # gets a good sampling of data, even when steps is small, we \n",
        "    # shuffle all the data before creating the Dataset object\n",
        "    idx = np.random.permutation(features.index)\n",
        "    raw_features = {\"pixels\":features.reindex(idx)}\n",
        "    raw_targets = np.array(labels[idx])\n",
        "   \n",
        "    ds = Dataset.from_tensor_slices((raw_features,raw_targets)) # warning: 2GB limit\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
        "    \n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(10000)\n",
        "    \n",
        "    # Return the next batch of data\n",
        "    feature_batch, label_batch = ds.make_one_shot_iterator().get_next()\n",
        "    return feature_batch, label_batch\n",
        "\n",
        "  return _input_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8zoGWAoohrwS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_predict_input_fn(features, labels, batch_size):\n",
        "  \"\"\"A custom input_fn for sending mnist data to the estimator for predictions.\n",
        "\n",
        "  Args:\n",
        "    features: The features to base predictions on.\n",
        "    labels: The labels of the prediction examples.\n",
        "\n",
        "  Returns:\n",
        "    A function that returns features and labels for predictions.\n",
        "  \"\"\"\n",
        "  def _input_fn():\n",
        "    raw_features = {\"pixels\": features.values}\n",
        "    raw_targets = np.array(labels)\n",
        "    \n",
        "    ds = Dataset.from_tensor_slices((raw_features, raw_targets)) # warning: 2GB limit\n",
        "    ds = ds.batch(batch_size)\n",
        "    \n",
        "        \n",
        "    # Return the next batch of data\n",
        "    feature_batch, label_batch = ds.make_one_shot_iterator().get_next()\n",
        "    return feature_batch, label_batch\n",
        "\n",
        "  return _input_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G6DjSLZMu8Um",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_linear_classification_model(\n",
        "    learning_rate,\n",
        "    steps,\n",
        "    batch_size,\n",
        "    training_examples,\n",
        "    training_targets,\n",
        "    validation_examples,\n",
        "    validation_targets):\n",
        "  \"\"\"Trains a linear classification model for the MNIST digits dataset.\n",
        "  \n",
        "  In addition to training, this function also prints training progress information,\n",
        "  a plot of the training and validation loss over time, and a confusion\n",
        "  matrix.\n",
        "  \n",
        "  Args:\n",
        "    learning_rate: An `int`, the learning rate to use.\n",
        "    steps: A non-zero `int`, the total number of training steps. A training step\n",
        "      consists of a forward and backward pass using a single batch.\n",
        "    batch_size: A non-zero `int`, the batch size.\n",
        "    training_examples: A `DataFrame` containing the training features.\n",
        "    training_targets: A `DataFrame` containing the training labels.\n",
        "    validation_examples: A `DataFrame` containing the validation features.\n",
        "    validation_targets: A `DataFrame` containing the validation labels.\n",
        "      \n",
        "  Returns:\n",
        "    The trained `LinearClassifier` object.\n",
        "  \"\"\"\n",
        "\n",
        "  periods = 10\n",
        "\n",
        "  steps_per_period = steps / periods  \n",
        "  # Create the input functions.\n",
        "  predict_training_input_fn = create_predict_input_fn(\n",
        "    training_examples, training_targets, batch_size)\n",
        "  predict_validation_input_fn = create_predict_input_fn(\n",
        "    validation_examples, validation_targets, batch_size)\n",
        "  training_input_fn = create_training_input_fn(\n",
        "    training_examples, training_targets, batch_size)\n",
        "  \n",
        "  # Create a LinearClassifier object.\n",
        "  my_optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)\n",
        "  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "  classifier = tf.estimator.LinearClassifier(\n",
        "      feature_columns=construct_feature_columns(),\n",
        "      n_classes=10,\n",
        "      optimizer=my_optimizer,\n",
        "      config=tf.estimator.RunConfig(keep_checkpoint_max=1)\n",
        "  )\n",
        "\n",
        "  # Train the model, but do so inside a loop so that we can periodically assess\n",
        "  # loss metrics.\n",
        "  print(\"Training model...\")\n",
        "  print(\"LogLoss error (on validation data):\")\n",
        "  training_errors = []\n",
        "  validation_errors = []\n",
        "  for period in range (0, periods):\n",
        "    # Train the model, starting from the prior state.\n",
        "    classifier.train(\n",
        "        input_fn=training_input_fn,\n",
        "        steps=steps_per_period\n",
        "    )\n",
        "  \n",
        "    # Take a break and compute probabilities.\n",
        "    training_predictions = list(classifier.predict(input_fn=predict_training_input_fn))\n",
        "    training_probabilities = np.array([item['probabilities'] for item in training_predictions])\n",
        "    training_pred_class_id = np.array([item['class_ids'][0] for item in training_predictions])\n",
        "    training_pred_one_hot = tf.keras.utils.to_categorical(training_pred_class_id,10)\n",
        "        \n",
        "    validation_predictions = list(classifier.predict(input_fn=predict_validation_input_fn))\n",
        "    validation_probabilities = np.array([item['probabilities'] for item in validation_predictions])    \n",
        "    validation_pred_class_id = np.array([item['class_ids'][0] for item in validation_predictions])\n",
        "    validation_pred_one_hot = tf.keras.utils.to_categorical(validation_pred_class_id,10)    \n",
        "    \n",
        "    # Compute training and validation errors.\n",
        "    training_log_loss = metrics.log_loss(training_targets, training_pred_one_hot)\n",
        "    validation_log_loss = metrics.log_loss(validation_targets, validation_pred_one_hot)\n",
        "    # Occasionally print the current loss.\n",
        "    print(\"  period %02d : %0.2f\" % (period, validation_log_loss))\n",
        "    # Add the loss metrics from this period to our list.\n",
        "    training_errors.append(training_log_loss)\n",
        "    validation_errors.append(validation_log_loss)\n",
        "  print(\"Model training finished.\")\n",
        "  # Remove event files to save disk space.\n",
        "  _ = map(os.remove, glob.glob(os.path.join(classifier.model_dir, 'events.out.tfevents*')))\n",
        "  \n",
        "  # Calculate final predictions (not probabilities, as above).\n",
        "  final_predictions = classifier.predict(input_fn=predict_validation_input_fn)\n",
        "  final_predictions = np.array([item['class_ids'][0] for item in final_predictions])\n",
        "  \n",
        "  \n",
        "  accuracy = metrics.accuracy_score(validation_targets, final_predictions)\n",
        "  print(\"Final accuracy (on validation data): %0.2f\" % accuracy)\n",
        "\n",
        "  # Output a graph of loss metrics over periods.\n",
        "  plt.ylabel(\"LogLoss\")\n",
        "  plt.xlabel(\"Periods\")\n",
        "  plt.title(\"LogLoss vs. Periods\")\n",
        "  plt.plot(training_errors, label=\"training\")\n",
        "  plt.plot(validation_errors, label=\"validation\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  \n",
        "  # Output a plot of the confusion matrix.\n",
        "  cm = metrics.confusion_matrix(validation_targets, final_predictions)\n",
        "  # Normalize the confusion matrix by row (i.e by the number of samples\n",
        "  # in each class)\n",
        "  cm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
        "  ax = sns.heatmap(cm_normalized, cmap=\"bone_r\")\n",
        "  ax.set_aspect(1)\n",
        "  plt.title(\"Confusion matrix\")\n",
        "  plt.ylabel(\"True label\")\n",
        "  plt.xlabel(\"Predicted label\")\n",
        "  plt.show()\n",
        "\n",
        "  return classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ItHIUyv2u8Ur",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " **이 형태의 선형 모델로 정확성을 얼마나 높일 수 있는지 5분 동안 확인해 보세요. 이 실습에서는 초매개변수 실험 범위를 배치 크기, 학습률, 단계 수로만 제한합니다.**\n",
        "\n",
        "정확성이 0.9를 초과하면 실행을 중단하세요."
      ]
    },
    {
      "metadata": {
        "id": "yaiIhIQqu8Uv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973
        },
        "outputId": "5e817c3b-0e92-4a23-a36d-a9682408be90"
      },
      "cell_type": "code",
      "source": [
        "classifier = train_linear_classification_model(\n",
        "             learning_rate=0.02,\n",
        "             steps=100,\n",
        "             batch_size=10,\n",
        "             training_examples=training_examples,\n",
        "             training_targets=training_targets,\n",
        "             validation_examples=validation_examples,\n",
        "             validation_targets=validation_targets)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model...\n",
            "LogLoss error (on validation data):\n",
            "  period 00 : 15.16\n",
            "  period 01 : 11.80\n",
            "  period 02 : 9.24\n",
            "  period 03 : 7.82\n",
            "  period 04 : 6.69\n",
            "  period 05 : 6.80\n",
            "  period 06 : 7.16\n",
            "  period 07 : 6.48\n",
            "  period 08 : 6.31\n",
            "  period 09 : 5.95\n",
            "Model training finished.\n",
            "Final accuracy (on validation data): 0.83\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFnCAYAAACLnxFFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwdAmIiKSCYY2ERGRTPw/44OY4pMMcjgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fa6506f3090>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAFnCAYAAACM3c9QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPdMR3tPXCe0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fa65003b6d0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "266KQvZoMxMv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " ### 해결 방법\n",
        "\n",
        "가능한 해결 방법 중 하나를 보려면 아래를 클릭하세요."
      ]
    },
    {
      "metadata": {
        "id": "lRWcn24DM3qa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " 다음은 약 0.9의 정확성을 달성하는 매개변수 세트입니다."
      ]
    },
    {
      "metadata": {
        "id": "TGlBMrUoM1K_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "_ = train_linear_classification_model(\n",
        "    learning_rate=0.03,\n",
        "    steps=1000,\n",
        "    batch_size=30,\n",
        "    training_examples=training_examples,\n",
        "    training_targets=training_targets,\n",
        "    validation_examples=validation_examples,\n",
        "    validation_targets=validation_targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mk095OfpPdOx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " ## 작업 2: 선형 분류자를 신경망으로 대체\n",
        "\n",
        "**위의 LinearClassifier를 [`DNNClassifier`](https://www.tensorflow.org/api_docs/python/tf/contrib/learn/DNNClassifier)로 대체하고 0.95 이상의 정확성을 보이는 매개변수 조합을 찾습니다.**\n",
        "\n",
        "드롭아웃 같은 정규화 방식을 추가로 실험해 볼 수도 있습니다. 이러한 추가 정규화 방식은 `DNNClassifier` 클래스의 설명에 기술되어 있습니다."
      ]
    },
    {
      "metadata": {
        "id": "rm8P_Ttwu8U4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#\n",
        "# YOUR CODE HERE: Replace the linear classifier with a neural network.\n",
        "#\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TOfmiSvqu8U9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " 적절한 모델이 확보되었으면 아래에서 로드할 테스트 데이터로 평가하여 검증세트에 대해 과적합되지 않았는지 재확인합니다.\n"
      ]
    },
    {
      "metadata": {
        "id": "evlB5ubzu8VJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnist_test_dataframe = pd.read_csv(\n",
        "  \"https://dl.google.com/mlcc/mledu-datasets/mnist_test.csv\",\n",
        "  sep=\",\",\n",
        "  header=None)\n",
        "\n",
        "test_targets, test_examples = parse_labels_and_features(mnist_test_dataframe)\n",
        "test_examples.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PDuLd2Hcu8VL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#\n",
        "# YOUR CODE HERE: Calculate accuracy on the test set.\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6sfw3LH0Oycm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " ### 해결 방법\n",
        "\n",
        "가능한 해결 방법을 보려면 아래를 클릭하세요."
      ]
    },
    {
      "metadata": {
        "id": "XatDGFKEO374",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " 아래 코드는 원래의 `LinearClassifer` 학습 코드와 거의 동일하지만, 차이점은 히든 유닛에 대한 초매개변수와 같은 NN 전용 구성이 포함되어 있다는 점입니다."
      ]
    },
    {
      "metadata": {
        "id": "kdNTx8jkPQUx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_nn_classification_model(\n",
        "    learning_rate,\n",
        "    steps,\n",
        "    batch_size,\n",
        "    hidden_units,\n",
        "    training_examples,\n",
        "    training_targets,\n",
        "    validation_examples,\n",
        "    validation_targets):\n",
        "  \"\"\"Trains a neural network classification model for the MNIST digits dataset.\n",
        "  \n",
        "  In addition to training, this function also prints training progress information,\n",
        "  a plot of the training and validation loss over time, as well as a confusion\n",
        "  matrix.\n",
        "  \n",
        "  Args:\n",
        "    learning_rate: An `int`, the learning rate to use.\n",
        "    steps: A non-zero `int`, the total number of training steps. A training step\n",
        "      consists of a forward and backward pass using a single batch.\n",
        "    batch_size: A non-zero `int`, the batch size.\n",
        "    hidden_units: A `list` of int values, specifying the number of neurons in each layer.\n",
        "    training_examples: A `DataFrame` containing the training features.\n",
        "    training_targets: A `DataFrame` containing the training labels.\n",
        "    validation_examples: A `DataFrame` containing the validation features.\n",
        "    validation_targets: A `DataFrame` containing the validation labels.\n",
        "      \n",
        "  Returns:\n",
        "    The trained `DNNClassifier` object.\n",
        "  \"\"\"\n",
        "\n",
        "  periods = 10\n",
        "  # Caution: input pipelines are reset with each call to train. \n",
        "  # If the number of steps is small, your model may never see most of the data.  \n",
        "  # So with multiple `.train` calls like this you may want to control the length \n",
        "  # of training with num_epochs passed to the input_fn. Or, you can do a really-big shuffle, \n",
        "  # or since it's in-memory data, shuffle all the data in the `input_fn`.\n",
        "  steps_per_period = steps / periods  \n",
        "  # Create the input functions.\n",
        "  predict_training_input_fn = create_predict_input_fn(\n",
        "    training_examples, training_targets, batch_size)\n",
        "  predict_validation_input_fn = create_predict_input_fn(\n",
        "    validation_examples, validation_targets, batch_size)\n",
        "  training_input_fn = create_training_input_fn(\n",
        "    training_examples, training_targets, batch_size)\n",
        "  \n",
        "  # Create the input functions.\n",
        "  predict_training_input_fn = create_predict_input_fn(\n",
        "    training_examples, training_targets, batch_size)\n",
        "  predict_validation_input_fn = create_predict_input_fn(\n",
        "    validation_examples, validation_targets, batch_size)\n",
        "  training_input_fn = create_training_input_fn(\n",
        "    training_examples, training_targets, batch_size)\n",
        "  \n",
        "  # Create feature columns.\n",
        "  feature_columns = [tf.feature_column.numeric_column('pixels', shape=784)]\n",
        "\n",
        "  # Create a DNNClassifier object.\n",
        "  my_optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)\n",
        "  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "  classifier = tf.estimator.DNNClassifier(\n",
        "      feature_columns=feature_columns,\n",
        "      n_classes=10,\n",
        "      hidden_units=hidden_units,\n",
        "      optimizer=my_optimizer,\n",
        "      config=tf.contrib.learn.RunConfig(keep_checkpoint_max=1)\n",
        "  )\n",
        "\n",
        "  # Train the model, but do so inside a loop so that we can periodically assess\n",
        "  # loss metrics.\n",
        "  print(\"Training model...\")\n",
        "  print(\"LogLoss error (on validation data):\")\n",
        "  training_errors = []\n",
        "  validation_errors = []\n",
        "  for period in range (0, periods):\n",
        "    # Train the model, starting from the prior state.\n",
        "    classifier.train(\n",
        "        input_fn=training_input_fn,\n",
        "        steps=steps_per_period\n",
        "    )\n",
        "  \n",
        "    # Take a break and compute probabilities.\n",
        "    training_predictions = list(classifier.predict(input_fn=predict_training_input_fn))\n",
        "    training_probabilities = np.array([item['probabilities'] for item in training_predictions])\n",
        "    training_pred_class_id = np.array([item['class_ids'][0] for item in training_predictions])\n",
        "    training_pred_one_hot = tf.keras.utils.to_categorical(training_pred_class_id,10)\n",
        "        \n",
        "    validation_predictions = list(classifier.predict(input_fn=predict_validation_input_fn))\n",
        "    validation_probabilities = np.array([item['probabilities'] for item in validation_predictions])    \n",
        "    validation_pred_class_id = np.array([item['class_ids'][0] for item in validation_predictions])\n",
        "    validation_pred_one_hot = tf.keras.utils.to_categorical(validation_pred_class_id,10)    \n",
        "    \n",
        "    # Compute training and validation errors.\n",
        "    training_log_loss = metrics.log_loss(training_targets, training_pred_one_hot)\n",
        "    validation_log_loss = metrics.log_loss(validation_targets, validation_pred_one_hot)\n",
        "    # Occasionally print the current loss.\n",
        "    print(\"  period %02d : %0.2f\" % (period, validation_log_loss))\n",
        "    # Add the loss metrics from this period to our list.\n",
        "    training_errors.append(training_log_loss)\n",
        "    validation_errors.append(validation_log_loss)\n",
        "  print(\"Model training finished.\")\n",
        "  # Remove event files to save disk space.\n",
        "  _ = map(os.remove, glob.glob(os.path.join(classifier.model_dir, 'events.out.tfevents*')))\n",
        "  \n",
        "  # Calculate final predictions (not probabilities, as above).\n",
        "  final_predictions = classifier.predict(input_fn=predict_validation_input_fn)\n",
        "  final_predictions = np.array([item['class_ids'][0] for item in final_predictions])\n",
        "  \n",
        "  \n",
        "  accuracy = metrics.accuracy_score(validation_targets, final_predictions)\n",
        "  print(\"Final accuracy (on validation data): %0.2f\" % accuracy)\n",
        "\n",
        "  # Output a graph of loss metrics over periods.\n",
        "  plt.ylabel(\"LogLoss\")\n",
        "  plt.xlabel(\"Periods\")\n",
        "  plt.title(\"LogLoss vs. Periods\")\n",
        "  plt.plot(training_errors, label=\"training\")\n",
        "  plt.plot(validation_errors, label=\"validation\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  \n",
        "  # Output a plot of the confusion matrix.\n",
        "  cm = metrics.confusion_matrix(validation_targets, final_predictions)\n",
        "  # Normalize the confusion matrix by row (i.e by the number of samples\n",
        "  # in each class)\n",
        "  cm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
        "  ax = sns.heatmap(cm_normalized, cmap=\"bone_r\")\n",
        "  ax.set_aspect(1)\n",
        "  plt.title(\"Confusion matrix\")\n",
        "  plt.ylabel(\"True label\")\n",
        "  plt.xlabel(\"Predicted label\")\n",
        "  plt.show()\n",
        "\n",
        "  return classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZfzsTYGPPU8I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classifier = train_nn_classification_model(\n",
        "    learning_rate=0.05,\n",
        "    steps=1000,\n",
        "    batch_size=30,\n",
        "    hidden_units=[100, 100],\n",
        "    training_examples=training_examples,\n",
        "    training_targets=training_targets,\n",
        "    validation_examples=validation_examples,\n",
        "    validation_targets=validation_targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qXvrOgtUR-zD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " 다음으로는 테스트 세트로 정확성을 검증합니다."
      ]
    },
    {
      "metadata": {
        "id": "scQNpDePSFjt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnist_test_dataframe = pd.read_csv(\n",
        "  \"https://dl.google.com/mlcc/mledu-datasets/mnist_test.csv\",\n",
        "  sep=\",\",\n",
        "  header=None)\n",
        "\n",
        "test_targets, test_examples = parse_labels_and_features(mnist_test_dataframe)\n",
        "test_examples.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EVaWpWKvSHmu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predict_test_input_fn = create_predict_input_fn(\n",
        "    test_examples, test_targets, batch_size=100)\n",
        "\n",
        "test_predictions = classifier.predict(input_fn=predict_test_input_fn)\n",
        "test_predictions = np.array([item['class_ids'][0] for item in test_predictions])\n",
        "  \n",
        "accuracy = metrics.accuracy_score(test_targets, test_predictions)\n",
        "print(\"Accuracy on test data: %0.2f\" % accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WX2mQBAEcisO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " ## 작업 3: 첫 번째 히든 레이어의 가중치 시각화\n",
        "\n",
        "몇 분 정도 시간을 들여 신경망을 살펴보면서 `weights_` 특성에 액세스하여 무엇을 학습했는지 확인해 보겠습니다.\n",
        "\n",
        "모델의 입력 레이어는 `28×28` 픽셀 입력 이미지에 해당하는 `784`개의 가중치를 갖습니다. 첫 번째 히든 레이어는 `784×N`개의 가중치를 갖는데, 여기에서 `N`은 해당 레이어의 노드 수입니다. `N`개의 `1×784` 가중치 배열 각각을 `28×28` 크기의 배열 `N` 개로 *재구성(reshape)*하면 이러한 가중치를 `28×28` 이미지로 되돌릴 수 있습니다.\n",
        "\n",
        "다음 셀을 실행하여 가중치를 도식화하세요. 이 셀을 실행하려면 \"classifier\"라는 `DNNClassifier`가 이미 학습된 상태여야 합니다."
      ]
    },
    {
      "metadata": {
        "id": "eUC0Z8nbafgG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(classifier.get_variable_names())\n",
        "\n",
        "weights0 = classifier.get_variable_value(\"dnn/hiddenlayer_0/kernel\")\n",
        "\n",
        "print(\"weights0 shape:\", weights0.shape)\n",
        "\n",
        "num_nodes = weights0.shape[1]\n",
        "num_rows = int(math.ceil(num_nodes / 10.0))\n",
        "fig, axes = plt.subplots(num_rows, 10, figsize=(20, 2 * num_rows))\n",
        "for coef, ax in zip(weights0.T, axes.ravel()):\n",
        "    # Weights in coef is reshaped from 1x784 to 28x28.\n",
        "    ax.matshow(coef.reshape(28, 28), cmap=plt.cm.pink)\n",
        "    ax.set_xticks(())\n",
        "    ax.set_yticks(())\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kL8MEhNgrx9N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " 신경망의 첫 번째 히든 레이어는 비교적 저수준인 특성을 모델링해야 하므로 가중치를 시각화해도 알아보기 어려운 형상이나 숫자의 일부만 표시될 가능성이 높습니다. 또한 수렴되지 않았거나 상위 레이어에서 무시하는, 근본적으로 노이즈인 뉴런이 보일 수도 있습니다.\n",
        "\n",
        "서로 다른 반복 단계에서 학습을 중지하면서 효과를 비교하면 흥미로울 수 있습니다.\n",
        "\n",
        "**분류자를 각각 10단계, 100단계, 1000단계 동안 학습시키고 이 시각화를 다시 실행해 보세요.**\n",
        "\n",
        "여러 가지 수렴 레벨에서 시각적으로 어떠한 차이점이 보이나요?"
      ]
    }
  ]
}